"""
Invisible Watermarking Module for AI-Generated Content Traceability

This module implements invisible watermarking to ensure accountability and responsibility
for AI-generated images. The watermarking system embeds a traceable signature that can
be detected even after common image manipulations.

Trustworthiness Focus:
- Accountability and Responsibility: Ensures AI-generated content is traceable
- Reliability and Robustness: Watermarks survive common attacks (cropping, compression, etc.)
"""

import numpy as np
from PIL import Image
import cv2
import hashlib


class InvisibleWatermarker:
    """
    Implements a robust invisible watermarking system using frequency domain embedding.
    
    The watermark is embedded in the DCT (Discrete Cosine Transform) domain, making it
    resistant to common image processing operations while remaining imperceptible.
    """
    
    def __init__(self, watermark_text="AI_GENERATED_FRANKAINSTEIN"):
        """
        Initialize the watermarker with a unique signature.
        
        Args:
            watermark_text (str): Text signature to embed in images
        """
        self.watermark_text = watermark_text
        # Generate a binary watermark pattern from the text
        self.watermark_bits = self._text_to_bits(watermark_text)
        self.watermark_length = len(self.watermark_bits)
        # Initialize original dimensions (will be set during embedding)
        self.original_height = None
        self.original_width = None
        
    def _text_to_bits(self, text):
        """Convert text to binary representation."""
        # Create a hash of the text for consistent binary pattern
        hash_obj = hashlib.md5(text.encode())
        hash_hex = hash_obj.hexdigest()
        # Convert hex to binary
        bits = ''.join(format(int(c, 16), '04b') for c in hash_hex)
        return [int(b) for b in bits]
    
    def embed_watermark(self, image, strength=0.2):
        """
        Embed invisible watermark into an image with improved robustness.
        
        Args:
            image (PIL.Image): Input image to watermark
            strength (float): Watermark embedding strength (0.0-1.0)
            Increased to 0.2 for better robustness while maintaining invisibility
            
        Returns:
            PIL.Image: Watermarked image
        """
        # Convert PIL to numpy array
        img_array = np.array(image.convert('RGB'))
        height, width = img_array.shape[:2]
        
        # Store original dimensions for resize handling
        self.original_height = height
        self.original_width = width
        
        # Ensure we have enough space for watermark
        if height < 64 or width < 64:
            # Resize if too small
            scale = max(64 / height, 64 / width)
            new_height = int(height * scale)
            new_width = int(width * scale)
            img_array = cv2.resize(img_array, (new_width, new_height))
            height, width = new_height, new_width
        
        # Split into YUV color space (watermark in Y channel for better robustness)
        yuv = cv2.cvtColor(img_array, cv2.COLOR_RGB2YUV)
        y_channel = yuv[:, :, 0].astype(np.float32)
        
        # Apply DCT to blocks
        block_size = 8
        watermarked_y = y_channel.copy()
        bit_index = 0
        
        # Embed watermark in DCT coefficients with improved robustness
        # Use multiple mid-frequency coefficients for redundancy
        for i in range(0, height - block_size, block_size):
            for j in range(0, width - block_size, block_size):
                if bit_index >= self.watermark_length:
                    break
                
                # Extract block
                block = y_channel[i:i+block_size, j:j+block_size]
                
                # Apply DCT
                dct_block = cv2.dct(block)
                
                # JPEG quantization-aware embedding
                # Standard JPEG quantization table (luminance) - these values determine
                # how coefficients are quantized during JPEG compression
                jpeg_quant_table = np.array([
                    [16, 11, 10, 16, 24, 40, 51, 61],
                    [12, 12, 14, 19, 26, 58, 60, 55],
                    [14, 13, 16, 24, 40, 57, 69, 56],
                    [14, 17, 22, 29, 51, 87, 80, 62],
                    [18, 22, 37, 56, 68, 109, 103, 77],
                    [24, 35, 55, 64, 81, 104, 113, 92],
                    [49, 64, 78, 87, 103, 121, 120, 101],
                    [72, 92, 95, 98, 112, 100, 103, 99]
                ])
                
                # Use lower-frequency coefficients with smaller quantization values
                # These survive JPEG compression much better
                # Positions: (1,2)=11, (2,1)=13, (0,2)=10, (2,0)=14, (1,1)=12
                # These have quantization values 10-14 instead of 51-57
                
                watermark_bit = self.watermark_bits[bit_index]
                
                # Calculate quantization-aware embedding values
                # For quality 85: Q_factor â‰ˆ 0.3, so we need to embed at least
                # quantization_step * Q_factor to survive
                # We'll embed at 2x the quantization step to be safe
                quality_factor = 0.3  # For quality 85
                
                # Primary positions: (1,2) and (2,1) - quantization values 11 and 13
                quant_1_2 = jpeg_quant_table[1, 2]  # = 11
                quant_2_1 = jpeg_quant_table[2, 1]  # = 13
                embed_1_2 = quant_1_2 * quality_factor * 2.5  # ~8.25
                embed_2_1 = quant_2_1 * quality_factor * 2.5  # ~9.75
                
                # Secondary positions: (0,2) and (2,0) - quantization values 10 and 14
                quant_0_2 = jpeg_quant_table[0, 2]  # = 10
                quant_2_0 = jpeg_quant_table[2, 0]  # = 14
                embed_0_2 = quant_0_2 * quality_factor * 2.0  # ~6.0
                embed_2_0 = quant_2_0 * quality_factor * 2.0  # ~8.4
                
                # Tertiary position: (1,1) - quantization value 12
                quant_1_1 = jpeg_quant_table[1, 1]  # = 12
                embed_1_1 = quant_1_1 * quality_factor * 1.5  # ~5.4
                
                # Apply quantization-aware embedding
                if watermark_bit == 1:
                    dct_block[1, 2] += embed_1_2
                    dct_block[2, 1] += embed_2_1
                    dct_block[0, 2] += embed_0_2
                    dct_block[2, 0] += embed_2_0
                    dct_block[1, 1] += embed_1_1
                else:
                    dct_block[1, 2] -= embed_1_2
                    dct_block[2, 1] -= embed_2_1
                    dct_block[0, 2] -= embed_0_2
                    dct_block[2, 0] -= embed_2_0
                    dct_block[1, 1] -= embed_1_1
                
                # Inverse DCT
                watermarked_block = cv2.idct(dct_block)
                watermarked_y[i:i+block_size, j:j+block_size] = watermarked_block
                
                bit_index += 1
            
            if bit_index >= self.watermark_length:
                break
        
        # Reconstruct image
        yuv[:, :, 0] = np.clip(watermarked_y, 0, 255).astype(np.uint8)
        watermarked_rgb = cv2.cvtColor(yuv, cv2.COLOR_YUV2RGB)
        
        return Image.fromarray(watermarked_rgb)
    
    def detect_watermark(self, image, threshold=0.5):
        """
        Detect watermark in an image with improved detection algorithm.
        
        Args:
            image (PIL.Image): Image to check for watermark
            threshold (float): Detection threshold (0.0-1.0)
            
        Returns:
            tuple: (detected: bool, confidence: float, extracted_bits: list)
        """
        # Convert PIL to numpy array
        img_array = np.array(image.convert('RGB'))
        height, width = img_array.shape[:2]
        
        # Handle resized images - try to restore to original size if possible
        # This helps with resize attacks
        if (hasattr(self, 'original_height') and hasattr(self, 'original_width') and 
            self.original_height is not None and self.original_width is not None):
            if abs(height - self.original_height) / self.original_height > 0.1:
                # Image was resized, try to restore
                scale_h = self.original_height / height
                scale_w = self.original_width / width
                if abs(scale_h - scale_w) < 0.1:  # Uniform scaling
                    new_height = self.original_height
                    new_width = self.original_width
                    img_array = cv2.resize(img_array, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
                    height, width = new_height, new_width
        
        # Resize if too small (same as embedding)
        if height < 64 or width < 64:
            scale = max(64 / height, 64 / width)
            new_height = int(height * scale)
            new_width = int(width * scale)
            img_array = cv2.resize(img_array, (new_width, new_height))
            height, width = new_height, new_width
        
        # Extract Y channel
        yuv = cv2.cvtColor(img_array, cv2.COLOR_RGB2YUV)
        y_channel = yuv[:, :, 0].astype(np.float32)
        
        # Extract watermark bits with improved algorithm
        block_size = 8
        extracted_bits = []
        bit_index = 0
        
        for i in range(0, height - block_size, block_size):
            for j in range(0, width - block_size, block_size):
                if bit_index >= self.watermark_length:
                    break
                
                # Extract block
                block = y_channel[i:i+block_size, j:j+block_size]
                
                # Apply DCT
                dct_block = cv2.dct(block)
                
                # Extract bit using the same coefficients as embedding
                # Use quantization-aware positions: (1,2), (2,1), (0,2), (2,0), (1,1)
                coeff_primary = dct_block[1, 2] + dct_block[2, 1]
                coeff_secondary = dct_block[0, 2] + dct_block[2, 0]
                coeff_tertiary = dct_block[1, 1]
                
                # Weighted combination (primary has most weight)
                coeff_sum = (coeff_primary * 1.0 + 
                            coeff_secondary * 0.8 + 
                            coeff_tertiary * 0.6)
                
                extracted_bit = 1 if coeff_sum > 0 else 0
                extracted_bits.append(extracted_bit)
                
                bit_index += 1
            
            if bit_index >= self.watermark_length:
                break
        
        # Calculate match with original watermark
        if len(extracted_bits) != len(self.watermark_bits):
            # Try with lower threshold if dimensions don't match (might be cropped)
            if len(extracted_bits) > 0:
                # Compare what we have
                min_len = min(len(extracted_bits), len(self.watermark_bits))
                matches = sum(1 for a, b in zip(extracted_bits[:min_len], 
                                                self.watermark_bits[:min_len]) if a == b)
                confidence = matches / len(self.watermark_bits)  # Normalize by expected length
                # Use lower threshold for cropped images
                detected = confidence >= (threshold * 0.8)
                return detected, confidence, extracted_bits
            return False, 0.0, extracted_bits
        
        matches = sum(1 for a, b in zip(extracted_bits, self.watermark_bits) if a == b)
        confidence = matches / len(self.watermark_bits)
        detected = confidence >= threshold
        
        return detected, confidence, extracted_bits


def add_watermark_to_image(image, watermark_text="AI_GENERATED_FRANKAINSTEIN", strength=0.2):
    """
    Convenience function to add watermark to an image.
    
    Args:
        image (PIL.Image): Image to watermark
        watermark_text (str): Watermark signature
        strength (float): Embedding strength
        
    Returns:
        PIL.Image: Watermarked image
    """
    watermarker = InvisibleWatermarker(watermark_text)
    # Store watermarker instance for detection (in real use, you'd use a global instance)
    # For now, we'll rely on the detection method's ability to handle resized images
    return watermarker.embed_watermark(image, strength)


def detect_watermark_in_image(image, watermark_text="AI_GENERATED_FRANKAINSTEIN", threshold=0.6):
    """
    Convenience function to detect watermark in an image.
    
    Args:
        image (PIL.Image): Image to check
        watermark_text (str): Expected watermark signature
        threshold (float): Detection threshold
        
    Returns:
        tuple: (detected: bool, confidence: float)
    """
    watermarker = InvisibleWatermarker(watermark_text)
    detected, confidence, _ = watermarker.detect_watermark(image, threshold)
    return detected, confidence

